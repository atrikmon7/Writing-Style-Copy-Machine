# Writing-Style-Copy-Machine 
In the recent days, as known to surely everyone by now, AI&ML are booming. Everyone is relying on the vast usefulness of these topics and appreciates it. Any major tedious tasks that took considerable amount of time and effort previously are now done much easily with the help AI&ML processes. In fact the usefulness of AI persisted long its boom in the commercial sector, and it was in build for a much longer time.In the present day, many of us have been used to chatbots, or intelligent text generating algorithms. In that context, we thought about a model that can copy a given writing style belonging to any person, then after being trained to that style can output text in that exact same style. 

As shown by Alan Turing during his Turing tests in 1950, mastering language is arguably Homo Sapiens’s greatest cognitive ability. And this portraying it through machines is a similarly difficult job. Can we build a machine that can master written and spoken language? This is the ultimate goal of NLP research, but it’s a bit too broad, so in practice researchers focus on more specific tasks, such as text classification, translation, summarization, question answering, and many more. A common approach for natural language tasks is to use custom recurrent neural networks (RNNs), starting with a character RNN, or a char-RNN, trained to predict next character in a sentence. For this, firstly we need a stateless RNN,  which learns from random portions of text at each iteration without any information about the rest of the text. Next, we will build a stateful RNN, which preserves the hidden state between training iterations and continues reading where it left off, allowing it to learn longer patterns. 

Keeping all the factors in mind and the huge procedure to make the exact model we aspire to make one day, in this project we’ve made a prototype model that some text with a basic understanding of the studied writing style.
